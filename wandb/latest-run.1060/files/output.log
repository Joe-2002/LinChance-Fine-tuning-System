
01/25/2024 22:18:52 - WARNING - llmtuner.extras.callbacks - Previous log file in this folder will be deleted.





























  5%|███████▉                                                                                                                                                                      | 49/1070 [00:59<18:02,  1.06s/it]






























  9%|████████████████                                                                                                                                                              | 99/1070 [02:00<19:21,  1.20s/it]






























 14%|████████████████████████                                                                                                                                                     | 149/1070 [02:59<15:07,  1.01it/s]






























 19%|████████████████████████████████▎                                                                                                                                            | 200/1070 [04:02<17:40,  1.22s/it][WARNING|trainer.py:2369] 2024-01-25 22:22:54,715 >> Checkpoint destination directory /root/LinChance-Fine-tuning-System/output_models/output_baichuan2/checkpoint-200 already exists and is non-empty.Saving will proceed but saved results may be invalid.
[INFO|trainer.py:2926] 2024-01-25 22:22:54,715 >> Saving model checkpoint to /root/LinChance-Fine-tuning-System/output_models/output_baichuan2/checkpoint-200
[INFO|tokenization_utils_base.py:2433] 2024-01-25 22:22:54,756 >> tokenizer config file saved in /root/LinChance-Fine-tuning-System/output_models/output_baichuan2/checkpoint-200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-01-25 22:22:54,756 >> Special tokens file saved in /root/LinChance-Fine-tuning-System/output_models/output_baichuan2/checkpoint-200/special_tokens_map.json
 19%|████████████████████████████████▍                                                                                                                                            | 201/1070 [04:03<16:27,  1.14s/it]































 23%|████████████████████████████████████████▍                                                                                                                                    | 250/1070 [05:04<16:47,  1.23s/it]
































 28%|████████████████████████████████████████████████▎                                                                                                                            | 299/1070 [06:09<18:00,  1.40s/it]
































 33%|████████████████████████████████████████████████████████▌                                                                                                                    | 350/1070 [07:13<12:12,  1.02s/it]






























 37%|████████████████████████████████████████████████████████████████▋                                                                                                            | 400/1070 [08:15<11:07,  1.00it/s][WARNING|trainer.py:2369] 2024-01-25 22:27:07,578 >> Checkpoint destination directory /root/LinChance-Fine-tuning-System/output_models/output_baichuan2/checkpoint-400 already exists and is non-empty.Saving will proceed but saved results may be invalid.
[INFO|trainer.py:2926] 2024-01-25 22:27:07,579 >> Saving model checkpoint to /root/LinChance-Fine-tuning-System/output_models/output_baichuan2/checkpoint-400
[INFO|tokenization_utils_base.py:2433] 2024-01-25 22:27:07,618 >> tokenizer config file saved in /root/LinChance-Fine-tuning-System/output_models/output_baichuan2/checkpoint-400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-01-25 22:27:07,618 >> Special tokens file saved in /root/LinChance-Fine-tuning-System/output_models/output_baichuan2/checkpoint-400/special_tokens_map.json
{'loss': 0.7109, 'learning_rate': 3.539144482162595e-05, 'epoch': 0.37}






























 42%|████████████████████████████████████████████████████████████████████████▊                                                                                                    | 450/1070 [09:17<13:46,  1.33s/it]































 47%|████████████████████████████████████████████████████████████████████████████████▊                                                                                            | 500/1070 [10:20<10:46,  1.13s/it]































 51%|████████████████████████████████████████████████████████████████████████████████████████▉                                                                                    | 550/1070 [11:22<11:19,  1.31s/it]






























 56%|█████████████████████████████████████████████████████████████████████████████████████████████████                                                                            | 600/1070 [12:24<10:14,  1.31s/it][INFO|trainer.py:2926] 2024-01-25 22:31:17,000 >> Saving model checkpoint to /root/LinChance-Fine-tuning-System/output_models/output_baichuan2/tmp-checkpoint-600
[INFO|tokenization_utils_base.py:2433] 2024-01-25 22:31:17,053 >> tokenizer config file saved in /root/LinChance-Fine-tuning-System/output_models/output_baichuan2/tmp-checkpoint-600/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-01-25 22:31:17,053 >> Special tokens file saved in /root/LinChance-Fine-tuning-System/output_models/output_baichuan2/tmp-checkpoint-600/special_tokens_map.json
{'loss': 0.6723, 'learning_rate': 2.105289360080177e-05, 'epoch': 0.56}






























 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                    | 649/1070 [13:26<08:46,  1.25s/it]































 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                           | 700/1070 [14:29<06:39,  1.08s/it]






























 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                    | 749/1070 [15:29<06:02,  1.13s/it]































 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                           | 799/1070 [16:31<06:25,  1.42s/it]
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                           | 800/1070 [16:32<06:15,  1.39s/it][INFO|trainer.py:2926] 2024-01-25 22:35:24,884 >> Saving model checkpoint to /root/LinChance-Fine-tuning-System/output_models/output_baichuan2/tmp-checkpoint-800
[INFO|tokenization_utils_base.py:2433] 2024-01-25 22:35:24,937 >> tokenizer config file saved in /root/LinChance-Fine-tuning-System/output_models/output_baichuan2/tmp-checkpoint-800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-01-25 22:35:24,937 >> Special tokens file saved in /root/LinChance-Fine-tuning-System/output_models/output_baichuan2/tmp-checkpoint-800/special_tokens_map.json




























 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                   | 849/1070 [17:31<04:18,  1.17s/it]






























 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                           | 899/1070 [18:31<03:15,  1.14s/it]































 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                   | 950/1070 [19:33<02:07,  1.06s/it]




























 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋           | 1000/1070 [20:32<01:28,  1.27s/it][INFO|trainer.py:2926] 2024-01-25 22:39:24,565 >> Saving model checkpoint to /root/LinChance-Fine-tuning-System/output_models/output_baichuan2/tmp-checkpoint-1000
[INFO|tokenization_utils_base.py:2433] 2024-01-25 22:39:24,618 >> tokenizer config file saved in /root/LinChance-Fine-tuning-System/output_models/output_baichuan2/tmp-checkpoint-1000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-01-25 22:39:24,619 >> Special tokens file saved in /root/LinChance-Fine-tuning-System/output_models/output_baichuan2/tmp-checkpoint-1000/special_tokens_map.json
{'loss': 0.6476, 'learning_rate': 7.036623822514049e-07, 'epoch': 0.93}






























 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 1049/1070 [21:33<00:24,  1.17s/it]












100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 1069/1070 [21:58<00:01,  1.32s/it]
{'train_runtime': 1329.1728, 'train_samples_per_second': 3.222, 'train_steps_per_second': 0.805, 'train_loss': 0.7259625015971817, 'epoch': 1.0}
***** train metrics *****
  epoch                    =        1.0
  train_loss               =      0.726
  train_runtime            = 0:22:09.17
  train_samples_per_second =      3.222
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1070/1070 [21:59<00:00,  1.41s/it][INFO|trainer.py:1962] 2024-01-25 22:40:52,015 >>
Training completed. Do not forget to share your model on huggingface.co/models =)
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1070/1070 [21:59<00:00,  1.23s/it]
[INFO|trainer.py:2926] 2024-01-25 22:40:52,019 >> Saving model checkpoint to /root/LinChance-Fine-tuning-System/output_models/output_baichuan2
[INFO|tokenization_utils_base.py:2433] 2024-01-25 22:40:52,074 >> tokenizer config file saved in /root/LinChance-Fine-tuning-System/output_models/output_baichuan2/tokenizer_config.json
[INFO|tokenization_utils_base.py:2442] 2024-01-25 22:40:52,075 >> Special tokens file saved in /root/LinChance-Fine-tuning-System/output_models/output_baichuan2/special_tokens_map.json
[INFO|modelcard.py:452] 2024-01-25 22:40:52,237 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}
Figure saved: /root/LinChance-Fine-tuning-System/output_models/output_baichuan2/training_loss.png
01/25/2024 22:40:52 - WARNING - llmtuner.extras.ploting - No metric eval_loss to plot.